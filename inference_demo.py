# -*- coding: utf-8 -*-
"""inference_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gh12rRiloqVMMNOYnRbeneaVRw08rA44
"""

!pip install -q transformers peft bitsandbytes accelerate sentencepiece

from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import torch

base_model = "microsoft/phi-2"
adapter_path = "./alpacare_lora_adapter"  # upload folder if needed

tokenizer = AutoTokenizer.from_pretrained(base_model)
base = AutoModelForCausalLM.from_pretrained(base_model, torch_dtype=torch.float16, device_map="auto")
model = PeftModel.from_pretrained(base, adapter_path)

def ask(prompt):
    full_prompt = f"### Instruction:\n{prompt}\n\n### Response:\n"
    inputs = tokenizer(full_prompt, return_tensors="pt").to("cuda")
    outputs = model.generate(**inputs, max_new_tokens=250)
    text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    print(text + "\n\nDisclaimer: This is educational only â€” consult a qualified clinician.")

# Example question
ask("Explain the importance of hydration during fever recovery.")